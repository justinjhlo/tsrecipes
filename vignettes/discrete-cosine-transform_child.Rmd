```{r setup}
library(tsrecipes)
library(tidyverse)
```

The primary application of the discrete cosine transform is in data compression:

> data compression is the art or science of representing information in a 
  more compact form. 
  - *Sayood, K. Introduction to Data Compression*
  
There's a natural connection here to machine learning:
we often way to represent high-dimensional features with fewer dimensions, 
to save memory and computing and improve accuracy. 

Statistical techniques like Principle Component Analysis (PCA) can even
be thought of as a [data compression](http://www.statistics4u.info/fundstat_eng/cc_pca_compress.html)
algorithm.

In data compression, correlation implies redundant information. 
Coding that removes or transforms these redundancies can also be beneficial
to machine learning, where highly correlated features, such values in a time
series, may harm accuracy.

Therefore, the discrete cosine transform offers

* uncorrelated features
* unsupervised dimensionality reduction


## What is the discrete cosine transform?

Sid Shanker provides an intuitive [introduction](https://squidarth.com/rc/math/2018/06/24/fourier.html)
to the discrete cosine transform in the context of data compression. 
In this article, I'll demonstrate how we can apply the discrete cosine transform
to a single time series.

### Time series as wiggles

Let's think about the *wiggliness* of time series.

```{r}
ts <- ethanol$ts[[1]]
ts_dct <- tibble(
  ts = ts,
  dct = fdct(ts),
  n = 1:length(ts)
)
```

```{r}
ts_recon <- ts_dct %>%
  mutate(
    dct_lf = ifelse(seq_along(dct) <= 20, dct, 0),
    ts_lf = dtt::dct(dct_lf, inverted = TRUE),
    dct_hf = ifelse(between(seq_along(dct), 20, 40), dct, 0),
    ts_hf = dtt::dct(dct_hf, inverted = TRUE)
  )

ts_recon %>%
  pivot_longer(c(ts, ts_hf, ts_lf)) %>%
  ggplot() +
  geom_line(aes(n, value, color = name))
```

The original time series (in red) can be thought of as a combination of different
wiggles. The blue line represents the *low-frequency* wiggles: these are wiggles
that go up and down relatively slowly.

The red line represents *high-frequency* wiggles, the wiggles that change 
quickly and sharply. 

If we add those two together
```r
ts_recon = ts_hf + ts_lf
```

we can reconstruct the general shape of the original time series.

```{r}
ts_recon %>%
  mutate(ts_recon = ts_hf + ts_lf) %>%
  pivot_longer(c(ts, ts_recon)) %>%
  ggplot() +
  geom_line(aes(n, value, color = name))
```

Except there's a major difference: I decreased the dimension of the time series
from 1751 to **40**. If I would have included all the dimensions, I would have
reproduced the time series exactly.

The dimensional reduction is the magic of the discrete cosine transform. 
It allows us to remove dimensions that don't contribute to the overall "shape"
of the time series. 

### Define wiggliness

Thanks to trigonometry (SOH CAH TOA) and 
[Joseph Fourier](https://en.wikipedia.org/wiki/Joseph_Fourier),
we can very precisely define what wiggliness means.

Imagine a sequence of cosine waves, with increasing wiggles. This sequence
needs to be the same length as the time series, 
but I'll only show a few to to demonstrate.

```{r}
cosine <- function(i, j = 1:60) {
  cos(pi / length(j) * i * (j + 1/2))
}
```

```{r}
fib <- c(1, 2, 3, 5, 8, 13)

cosine1 <- ts_recon %>%
  rowwise() %>%
  mutate(
    cosine = list(cosine(n, j = 1:1751)),
    cosine_scale = list(dct * cosine),
    i = list(1:1751)
  ) %>%
  filter(n %in% fib) %>%
  unnest(c(i, cosine, cosine_scale)) %>%
  ggplot() +
  geom_line(aes(i, cosine)) +
  facet_wrap(~n) +
  labs(x = NULL, y = NULL)

cosine1
```

As we saw in the previous example, there are cases where we can add up wiggles
to get back the original time series. But these cosine waves won't do, 
because each only ranges from -1 to 1. Our time series ranged from -1 to 2.

The discrete cosine transforms provides the amplitudes for this cosine sequence,
for any time series.
We can multiple the waves by the amplitudes to see how much each wave
contributes to the reconstruction.

```{r}
cosine1_scaled <- ts_recon %>%
  rowwise() %>%
  mutate(
    cosine = list(cosine(n, j = 1:1751)),
    cosine_scale = list(dct * cosine),
    i = list(1:1751)
  ) %>%
  filter(n %in% fib) %>%
  unnest(c(i, cosine, cosine_scale)) %>%
  ggplot() +
  geom_line(aes(i, cosine_scale)) +
  facet_wrap(~n) +
  labs(x = NULL, y = NULL)

cosine1_scaled
```

The waves flip and grow based on the sign and size of the coefficients. 
Some are very small, but some seem unrealistically large like #3, 
ranging from -1000 to 1000. But rest assured, we can use these to reconstruct
the original time series.

Also, remember that this sequence of cosine waves get more wiggly as time goes
on. If we look at the amplitudes (discrete cosine transform coefficients)
of the time series, we see that it trends toward zero.

```{r}
ts_recon %>%
  ggplot(aes(n, dct)) +
  geom_line() + 
  geom_smooth() +
  scale_y_log10(labels = scales::comma)
```

This means that the *really* wiggly cosine waves don't contribute very much
to the time series, which is why we could reconstruct with only 50 features.

The high frequency features don't contribute much, because the overall
shape of the time series is a big, low-frequency hump.


### Wiggles waver between time series

You can't necessarily assume that high frequencies are irrelevant.
It depends on the characteristics of the time series. For example:


```{r}
ts <- prices$ts[[1]]
ts_dct <- tibble(
  ts = ts,
  dct = fdct(ts),
  n = 1:length(ts)
)
```

```{r}
ts_recon <- ts_dct %>%
  mutate(
    dct_lf = ifelse(seq_along(dct) <= 20, dct, 0),
    ts_lf = dtt::dct(dct_lf, inverted = TRUE),
    dct_hf = ifelse(between(seq_along(dct), 40, 60), dct, 0),
    ts_hf = dtt::dct(dct_hf, inverted = TRUE)
  )

ts_recon %>%
  pivot_longer(c(ts, ts_hf, ts_lf)) %>%
  ggplot() +
  geom_line(aes(n, value, color = name))
```

in this time series, it's the high frequency green time series that's better a
better reconstruction of the original.

Dimensionality reduction with discrete cosine transform depends on the 
characteristics of the time series, so you either need to use your judgment
or tune the number of coefficients selected.




